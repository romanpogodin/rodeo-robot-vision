{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Video processing with OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import serial\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify camera/device number (usually 0)\n",
    "camera = 0\n",
    "\n",
    "# Specifiy number of frames to acquire\n",
    "num_frames = 1000\n",
    "\n",
    "# Open camera stream\n",
    "cam = cv2.VideoCapture(camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20, 20))\n",
    "\n",
    "min_perimeter = 15\n",
    "\n",
    "# Make space for intermediate images (of correct data type)\n",
    "# gray = np.zeros((height, width), dtype = np.uint8)\n",
    "# gray_float = np.zeros((height, width), dtype = np.float32)\n",
    "# previous = np.zeros((height, width), dtype = np.float32)\n",
    "# difference = np.zeros((height, width), dtype = np.float32)\n",
    "\n",
    "# cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "# cv2.resizeWindow('image', 600, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup SimpleBlobDetector parameters.\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "# # Change thresholds\n",
    "# params.minThreshold = 10\n",
    "# params.maxThreshold = 200\n",
    " \n",
    "# Filter by Area.\n",
    "params.filterByArea = False # coulde be faster without it\n",
    "params.minArea = 1500\n",
    " \n",
    "# # Filter by Circularity\n",
    "params.filterByCircularity = False\n",
    "# params.minCircularity = 0.1\n",
    " \n",
    "# # Filter by Convexity\n",
    "params.filterByConvexity = False\n",
    "# params.minConvexity = 0.87\n",
    " \n",
    "# # Filter by Inertia\n",
    "params.filterByInertia = False\n",
    "# params.minInertiaRatio = 0.01\n",
    " \n",
    "# Create a detector with the parameters\n",
    "detector = cv2.SimpleBlobDetector_create(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_transformed_image(image, anchor_points, new_anchor_points):\n",
    "#     rows, cols, _ = image.shape\n",
    "\n",
    "#     new_points = new_anchor_points\n",
    "    \n",
    "#     matrix = cv2.getAffineTransform(new_anchor_points, anchor_points)\n",
    "    \n",
    "#     return cv2.warpAffine(image, matrix, (cols, rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_anchor_points(init_points):\n",
    "#     distances = np.sum(init_points ** 2, axis=0)\n",
    "#     first_point_ind = np.argmin(distances)\n",
    "    \n",
    "#     distanes = np.sum((init_points - \n",
    "#                        np.repeat(init_points[:, first_point_ind].reshape((2, 1)), \n",
    "#                                  4, axis=1)) ** 2, axis=0)\n",
    "#     indices = np.argsort(distances)\n",
    "#     np.sort(np.sqrt(distances))\n",
    "    \n",
    "#     anchors = init_points[:, indices]\n",
    "    \n",
    "#     new_anchors = anchors.copy() np.repeat(init_points[:, 0].reshape((2, 1))\n",
    "    \n",
    "#     if np.arccos(() / (np.linalg.norm(anchors)))\n",
    "    \n",
    "#     return anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_frames = 1000\n",
    "\n",
    "kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20, 20))\n",
    "\n",
    "def filtrate_red(hsv_masks, clear_noise=True, show_filtered=False, min_perimeter=15):\n",
    "    # Create a VideoCapture object and read from input file\n",
    "    # If the input is the camera, pass 0 instead of the video file name\n",
    "    \n",
    "    cam = cv2.VideoCapture(0)\n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if (cam.isOpened()== False):\n",
    "        print(\"Error opening video stream or file\")\n",
    "\n",
    "    # Get image size\n",
    "    width = int(cam.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cam.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Read until video is completed\n",
    "    for i in range(0, num_frames):\n",
    "        if not cam.isOpened():\n",
    "            break\n",
    "\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cam.read()    \n",
    "        if ret == True:\n",
    "            hsv_img = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            frame_threshed = np.zeros((height, width), dtype=np.uint8)\n",
    "            for each_mask in hsv_masks:\n",
    "                frame_threshed += cv2.inRange(hsv_img, each_mask[0], each_mask[1])\n",
    "\n",
    "            if clear_noise:\n",
    "                frame_threshed = cv2.morphologyEx(frame_threshed, cv2.MORPH_OPEN, kernel_open)\n",
    "                frame_threshed = cv2.morphologyEx(frame_threshed, cv2.MORPH_CLOSE, kernel_close)\n",
    "                \n",
    "            _, contours, hierarchy = cv2.findContours(frame_threshed, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            backtorgb = cv2.cvtColor(frame_threshed, cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "            if show_filtered:\n",
    "                image_to_show = backtorgb\n",
    "            else:\n",
    "                image_to_show = frame\n",
    "            \n",
    "            for i in range(len(contours)):\n",
    "                if len(contours[i]) > min_perimeter:\n",
    "                    cv2.drawContours(image_to_show, contours, i, (0, 0, 255), 2)  \n",
    "                    \n",
    "                    ellipse = cv2.fitEllipse(contours[i])\n",
    "                    cv2.ellipse(image_to_show, ellipse, (0, 255, 0), 2)\n",
    "#                     print(ellipse)\n",
    "            \n",
    "#             if np.all(anchor_set):\n",
    "#                 return image_to_show, anchor_points, default_anchors\n",
    "#                 image_to_show = get_transformed_image(image_to_show, anchor_points, default_anchors)\n",
    "                \n",
    "            \n",
    "            #  cv2.drawContours(backtorgb, contours, -1, (0, 0, 255), 2)  \n",
    "\n",
    "            cv2.imshow('Frame', image_to_show)\n",
    "\n",
    "            #  plt.imshow(backtorgb)\n",
    "            \n",
    "            # Press Q on keyboard to  exit\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Break the loop\n",
    "        else: \n",
    "            break\n",
    "\n",
    "    # When everything done, release the video capture object\n",
    "    cam.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lower red mask (0-10)\n",
    "# upper red mask (170-180)\n",
    "hsv_masks = [[np.array([0, 110, 0], np.uint8), \n",
    "              np.array([10, 255, 255], np.uint8)],\n",
    "             [np.array([160, 110, 0], np.uint8), \n",
    "              np.array([180, 255, 255], np.uint8)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "filtrate_red(hsv_masks, clear_noise=True, show_filtered=False, min_perimeter=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hsv_masks(color='red'):\n",
    "    if color == 'red':\n",
    "        return [[np.array([0, 80, 0], np.uint8),\n",
    "                 np.array([10, 255, 255], np.uint8)],\n",
    "                [np.array([160, 80, 0], np.uint8), \n",
    "                 np.array([180, 255, 255], np.uint8)]]\n",
    "\n",
    "    if color == 'green':\n",
    "        return [[np.array([45, 100, 100], np.uint8), \n",
    "                 np.array([75, 255, 255], np.uint8)]]\n",
    "        \n",
    "    print('Color must be green or red')\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear_binary_from_noise(image_threshed):\n",
    "    kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20, 20))\n",
    "\n",
    "    image_threshed = cv2.morphologyEx(image_threshed, cv2.MORPH_OPEN, kernel_open)\n",
    "    image_threshed = cv2.morphologyEx(image_threshed, cv2.MORPH_CLOSE, kernel_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_colored_objects(hsv_img, min_perimeter, clear_noise=True, color='red'):\n",
    "    height, width = hsv_img.shape[0:2]\n",
    "    \n",
    "    image_threshed = np.zeros((height, width), dtype=np.uint8)\n",
    "    \n",
    "    hsv_masks = get_hsv_masks(color)\n",
    "    \n",
    "    for each_mask in hsv_masks:\n",
    "        image_threshed += cv2.inRange(hsv_img, each_mask[0], each_mask[1])\n",
    "\n",
    "    if clear_noise:\n",
    "        clear_binary_from_noise(image_threshed)\n",
    "\n",
    "    _, contours, hierarchy = cv2.findContours(image_threshed, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    circles = []\n",
    "    for contour in contours:\n",
    "        if len(contour) > min_perimeter:\n",
    "            radius = np.sqrt(np.sum((contour[len(contour) // 2] - contour[0]) ** 2)) / 2\n",
    "            circles.append([0.5 * (contour[0] + contour[len(contour) // 2]).reshape(2), radius])\n",
    "\n",
    "    return circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(cam, min_perimeter, show_picture=True, clear_noise=True):\n",
    "    # Initial processing\n",
    "\n",
    "    ret, image = cam.read()    \n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Cannot read a frame\")\n",
    "        return 1\n",
    "    \n",
    "    hsv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    rodeo_circles = detect_colored_objects(hsv_img, min_perimeter, \n",
    "                                           clear_noise, color='red')\n",
    "    obstacle_circles = detect_colored_objects(hsv_img, min_perimeter, \n",
    "                                              clear_noise, color='green')\n",
    "\n",
    "    for circle in rodeo_circles:\n",
    "        cv2.circle(image, tuple(circle[0].astype('int')), \n",
    "                   circle[1].astype('int'), (0, 0, 255), 2)\n",
    "        \n",
    "    for circle in obstacle_circles:\n",
    "        cv2.circle(image, tuple(circle[0].astype('int')), \n",
    "                   circle[1].astype('int'), (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('Frame', image)\n",
    "    \n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        return 1\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_decison():\n",
    "    return\n",
    "\n",
    "def make_decision():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_rodeo(max_time=1000, min_perimeter=15):\n",
    "    # Connect to the transmitter\n",
    "    \n",
    "    # Connect to a webcam\n",
    "    \n",
    "    cam = cv2.VideoCapture(0)\n",
    "    if (cam.isOpened() == False):\n",
    "        print(\"Error opening video stream or file\")\n",
    "\n",
    "#     width = int(cam.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     height = int(cam.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Process video\n",
    "    for time in range(max_time):\n",
    "        if not cam.isOpened():\n",
    "            print(\"Camera is not opened\")\n",
    "            break\n",
    "            \n",
    "        ret = process_frame(cam, min_perimeter=min_perimeter)\n",
    "        \n",
    "        if ret:\n",
    "            break\n",
    "        \n",
    "#         make_decision()\n",
    "        \n",
    "#         send_decision()\n",
    "        \n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_rodeo(max_time=10000, min_perimeter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write data to Arduino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ser = serial.Serial('COM9', 9600) # Establish the connection on a specific port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ser.write(b'B') # Convert the decimal number to ASCII then send it to the Arduino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(ser.readline()) # Read the newest output from the Arduino\n",
    "# sleep(0.1) # Delay for one tenth of a second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Robot control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import serial\n",
    "from time import sleep\n",
    "import serial\n",
    "from pynput import keyboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyboard control with pynput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ser = serial.Serial('COM9', 9600)\n",
    "\n",
    "def on_press(key):\n",
    "    try:\n",
    "        if 'w' == '{0}'.format(key)[1]:\n",
    "            ser.write(b'w')\n",
    "            sleep(0.0001)\n",
    "                    \n",
    "        if 'a' == '{0}'.format(key)[1]:\n",
    "            ser.write(b'a')\n",
    "            sleep(0.0001)\n",
    "\n",
    "        if 's' == '{0}'.format(key)[1]:\n",
    "            ser.write(b's')\n",
    "            sleep(0.0001)\n",
    "\n",
    "        if 'd' == '{0}'.format(key)[1]:\n",
    "            ser.write(b'd')\n",
    "            sleep(0.0001)\n",
    "            \n",
    "        if 'c' == '{0}'.format(key)[1]:\n",
    "            ser.write(b'c')\n",
    "            sleep(0.0001)\n",
    "    except AttributeError:\n",
    "        pwrint('special key {0} pressed'.format(key))\n",
    "\n",
    "def on_release(key):\n",
    "#     print('{0} released'.format(key))\n",
    "    if key == keyboard.Key.esc:\n",
    "        # Stop listener\n",
    "        return False\n",
    "\n",
    "# Collect events until released\n",
    "with keyboard.Listener(\n",
    "        on_press=on_press,\n",
    "        on_release=on_release) as listener:\n",
    "    listener.join()\n",
    "    \n",
    "ser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyboard control with OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.imshow('Frame', np.zeros((200, 200)))\n",
    "while (True):\n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "                    \n",
    "    if cv2.waitKey(25) & 0xFF == ord('w'):\n",
    "        ser.write(b'w')\n",
    "        sleep(0.001)\n",
    "                    \n",
    "    if cv2.waitKey(25) & 0xFF == ord('a'):\n",
    "        ser.write(b'a')\n",
    "        sleep(0.001)\n",
    "                    \n",
    "    if cv2.waitKey(25) & 0xFF == ord('s'):\n",
    "        ser.write(b's')\n",
    "        sleep(0.001)\n",
    "                    \n",
    "    if cv2.waitKey(25) & 0xFF == ord('d'):\n",
    "        ser.write(b'd')\n",
    "        sleep(0.001)\n",
    "\n",
    "ser.close()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
